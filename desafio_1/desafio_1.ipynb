{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ue5hxxkdAQJg"},"source":["<img src=\"https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## Vectorización\n"]},{"cell_type":"code","execution_count":58,"metadata":{"id":"kCED1hh-Ioyf"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":59,"metadata":{"id":"PUbfVnzIIoMj"},"outputs":[],"source":["def cosine_similarity(a, b):\n","    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))"]},{"cell_type":"markdown","metadata":{"id":"DMOa4JPSCJ29"},"source":["### Datos"]},{"cell_type":"code","execution_count":60,"metadata":{"id":"RIO7b8GjAC17"},"outputs":[],"source":["#corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])\n","\n","corpus = np.array([\"que bueno que esta\", \"esta muy bueno\", \"esta excelente\"])"]},{"cell_type":"markdown","metadata":{"id":"8WqdaTmO8P1r"},"source":["Documento 1 --> que dia es hoy \\\n","Documento 2 --> martes el dia de hoy es martes \\\n","Documento 3 --> martes muchas gracias"]},{"cell_type":"markdown","metadata":{"id":"FVHxBRNzCMOS"},"source":["### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n","- Cada documento transformarlo en una lista de términos\n","- Armar un vector de términos no repetidos de todos los documentos"]},{"cell_type":"code","execution_count":61,"metadata":{"id":"3ZqTOZzDI7uv"},"outputs":[{"name":"stdout","output_type":"stream","text":["['bueno', 'esta', 'excelente', 'muy', 'que']\n"]}],"source":["# separa en términos\n","def vocabulario(c) -> list:\n","    l = c.split()\n","    return l\n","\n","# elimina duplicados\n","terms = list(set(vocabulario(corpus[0]) + vocabulario(corpus[1]) + vocabulario(corpus[2])))\n","\n","print(terms)\n"]},{"cell_type":"markdown","metadata":{"id":"RUhH983FI7It"},"source":["### 2- OneHot encoding\n","Data una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"]},{"cell_type":"code","execution_count":62,"metadata":{"id":"Os0AAQo6I6Z1"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[1, 1, 0, 0, 1], [1, 1, 0, 1, 0], [0, 1, 1, 0, 0]]\n"]}],"source":["def oneHotEncodig(terms, corpus):\n","\n","    y = 0\n","    a = [[0 for _ in range(len(terms))] for _ in range(len(corpus))]\n","\n","    for c in corpus:\n","        words = c.split()\n","        for w in words:\n","            a[y][terms.index(w)] = 1\n","        y+=1\n","    return a\n","\n","ohe = oneHotEncodig(terms,corpus)\n","\n","print(ohe)"]},{"cell_type":"markdown","metadata":{"id":"IIyWGmCpJVQL"},"source":["### 3- Vectores de frecuencia\n","Data una lista de textos, devolver una matriz con la representación de frecuencia de estos"]},{"cell_type":"code","execution_count":63,"metadata":{"id":"yqij_7eHJbUi"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[1, 1, 0, 0, 2], [1, 1, 0, 1, 0], [0, 1, 1, 0, 0]]\n"]}],"source":["def vectorFrecuencia(terms, corpus):\n","\n","    y = 0\n","    a = [[0 for _ in range(len(terms))] for _ in range(len(corpus))]\n","\n","    for c in corpus:\n","        words = c.split()\n","        for w in words:\n","            a[y][terms.index(w)] = a[y][terms.index(w)] + 1\n","        y+=1\n","    return a\n","\n","f = vectorFrecuencia(terms,corpus)\n","\n","print(f)"]},{"cell_type":"markdown","metadata":{"id":"z_Ot8HvWJcBu"},"source":["### 4- TF-IDF\n","Data una lista de textos, devolver una matriz con la representacion TFIDF"]},{"cell_type":"code","execution_count":64,"metadata":{"id":"waG_oWtpJjRw"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.17609125905568124, 0.0, 0.0, 0.0, 0.9542425094393249], [0.17609125905568124, 0.0, 0.0, 0.47712125471966244, 0.0], [0.0, 0.0, 0.47712125471966244, 0.0, 0.0]]\n"]}],"source":["import math\n","\n","def get_idf(terms, corpus):\n","    \n","    n = len(corpus)\n","\n","    ohe = oneHotEncodig(terms, corpus)\n","\n","    df = [sum(x) for x in zip(*ohe)]\n","\n","    idf = [math.log((n/x), 10) for x in df]\n","\n","    return idf\n","\n","\n","def get_tfidf(terms, corpus):\n","\n","    tf = vectorFrecuencia(terms, corpus)\n","\n","    idf = get_idf(terms, corpus)\n","    \n","    tf_idf = tf\n","    for i in range(len(tf)):\n","        for j in range(len(tf[0])):            \n","            tf_idf[i][j] = tf[i][j]*idf[j]\n","            \n","    return tf_idf\n","\n","\n","tf_idf = get_tfidf(terms, corpus)\n","\n","print(tf_idf)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"xMcsfndWJjm_"},"source":["### 5 - Comparación de documentos\n","Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno"]},{"cell_type":"code","execution_count":110,"metadata":{"id":"CZdiop6IJpZN"},"outputs":[{"data":{"text/plain":["[('que bueno que esta', 1.0000000000000002),\n"," ('esta muy bueno', 0.6666666666666667),\n"," ('esta excelente', 0.40824829046386296)]"]},"execution_count":110,"metadata":{},"output_type":"execute_result"}],"source":["def doc_comp(terms, corpus, idx):\n","\n","    m = oneHotEncodig(terms, corpus)    # se utiliza one hot encoding como metodología de vectorización\n","\n","    idx2 = []\n","\n","    for i in range(len(corpus)):\n","        \n","        idx2.append(cosine_similarity(m[idx], m[i]))\n","        \n","    zipped = zip( idx2, corpus)\n","\n","    corpus = [(i, j) for j, i in sorted(zipped, reverse=True)] \n","\n","    # corpus = [i for _, i in sorted(zipped, reverse=True)]  # de esta forma se devuelve el corpus original sin la similutud coseno\n","    \n","    return corpus\n","\n","doc_comp(terms, corpus, 0)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO5fRYTpympAwJSVbric6dW","collapsed_sections":[],"name":"1a - word2vec.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}
